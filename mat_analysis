---
title: "Test"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
CMAT data
Loading data and cleaning
```{r}
library(lubridate)
library(dplyr)
library(naniar)
library(tidyr)
library(prettyR)
setwd("T:/CRI_Research/telehealth_evaluation/CCHBC_big_picture/social_determinants_of_health_docs/Data/mat_data")
c_mat = read.csv("SPARS_rawdata_11.13.2020_C-MAT.csv", header = TRUE, na.strings = c(-9, -1, -8, -7, -6, -5))

c_mat_clean = c_mat %>%
  ### Only 6-months data because you don't have enough for pre and post with telehealth
  filter(InterviewType == 2) %>%
  mutate(InterviewDate = mdy(InterviewDate)) %>%
  ### Remove data with NAs for dates
  filter(InterviewDate > "2000-01-01") %>%
  mutate(telehealth = if_else(InterviewDate >= "2020-04-01", 1, 0)) %>%
  dplyr::select(ClientID, InterviewType, InterviewDate, Icd10CodeOne, Age, EmployStatus, Gender, HispanicLatino, RaceWhite, DAUseAlcoholDays, DAUseIllegDrugsDays, CocaineCrackDays, MarijuanaHashDays, OpiatesHeroinDays, OpiatesMorphineDays, OpiatesDiluadidDays, OpiatesDemerolDays, OpiatesPercocetDays, OpiatesDarvonDays, OpiatesCodeineDays, OpiatesTylenolDays, OpiatesOxycoDays, NonPresMethadoneDays, HallucPsychDays, MethamDays, BenzodiazepinesDays, BarbituatesDays, NonPrescGhbDays, KetamineDays, OtherTranquilizersDays, InhalantsDays, OtherIllegalDrugsDays, InjectedDrugs, LivingWhere, LivingConditionsSatisfaction, ImpactStress, ImpactActivity, ImpactEmotional, EducationYears, ArrestedDays, NrCrimes, LifeQuality, HealthSatisfaction, EnoughEnergyForEverydayLife, PerformDailyActivitiesSatisfaction, SelfSatisfaction, Depression, Anxiety, ViolentBehavior, Suicide, PsycholEmotMedication, PsycholEmotImpact, AnyViolence, PhysicallyHurt, telehealth) %>%
  rowwise() %>% 
      mutate(
        substance_days = mean(c_across(11:33)),
        sat = mean(c_across(43:46)),
        dep_anx = mean(c_across(47:48))) %>%
  ### Reverse code sat so higher values are better
  mutate(sat = 6-sat) %>%
  ### Make 1 and 2 employed part time or full time
  mutate(employed_bin = case_when(
    EmployStatus == 1 ~ 1, 
    EmployStatus == 2 ~ 1,
    TRUE ~ 0)) %>%
  drop_na()
  
c_mat_clean %>%
  dplyr::select(EmployStatus, employed_bin)


```
CMAT descriptives
```{r}
dim(c_mat_clean)
apply(c_mat_clean[50:58], 2, function(x){describe.factor(x)})
summary(c_mat_clean)
```
CMAT days, sat, and dep_anx just mean differences
Sub use is in average days and depression and anxiety is in average days
For the specifics about the type of MAT talk to Ellen
```{r}
library(descr)
library(tibble)
means_compare_dat = c_mat_clean[c("substance_days", "sat", "dep_anx")]
out_means_compare = list()
p_change_out = list()
wil_out = list()

for(i in 1:length(means_compare_dat)){
  out_means_compare[[i]] = compmeans(means_compare_dat[[i]], c_mat_clean$telehealth)
  p_change_out[[i]] = round((out_means_compare[[i]][2,1] - out_means_compare[[i]][1,1]) / out_means_compare[[i]][1,1],2)
  wil_out[[i]] = wilcox.test(means_compare_dat[[i]] ~ c_mat_clean$telehealth)
}

names(out_means_compare) = c("substance_days", "sat", "dep_anx")
out_means_compare
names(p_change_out) = c("substance_days", "sat", "dep_anx" )
p_change_out
names(wil_out) = c("substance_days", "sat", "dep_anx")
wil_out
```
Try IPW weighting with log of Bayesian t-test

ClientID, InterviewType, InterviewDate, Icd10CodeOne, Age, Employment, Gender, HispanicLatino, RaceWhite, DAUseAlcoholDays, DAUseIllegDrugsDays, CocaineCrackDays, MarijuanaHashDays, OpiatesHeroinDays, OpiatesMorphineDays, OpiatesDiluadidDays, OpiatesDemerolDays, OpiatesPercocetDays, OpiatesDarvonDays, OpiatesCodeineDays, OpiatesTylenolDays, OpiatesOxycoDays, NonPresMethadoneDays, HallucPsychDays, MethamDays, BenzodiazepinesDays, BarbituatesDays, NonPrescGhbDays, KetamineDays, OtherTranquilizersDays, InhalantsDays, OtherIllegalDrugsDays, InjectedDrugs, LivingWhere, LivingConditionsSatisfaction, ImpactStress, ImpactActivity, ImpactEmotional, EducationYears, ArrestedDays, NrCrimes, LifeQuality, HealthSatisfaction, EnoughEnergyForEverydayLife, PerformDailyActivitiesSatisfaction, SelfSatisfaction, Depression, Anxiety, ViolentBehavior, Suicide, PsycholEmotMedication, PsycholEmotImpact, AnyViolence, PhysicallyHurt, telehealth

```{r}
library(pscl)
c_mat_clean
ipw_cmat = glm(telehealth ~  Age + employed_bin + Gender + RaceWhite + substance_days + sat + dep_anx, data = clean_compare_dat_long, family = "binomial")
predict_treat_prob = predict(ipw_cmat, type = "response")
ipw_var = 1/predict_treat_prob
### Don't seem to be any outliers in the weights 
range(scale(ipw_var))
### With 400 samples we expect a few samples (6) to be at or above 3  and only 3.9
describe.factor(scale(ipw_var))

c_mat_clean = cbind(clean_compare_dat_long, ipw_var)

test_model_freq = lm(log() ~, data = clean_compare_dat_long,  weights = ipw_var)
summary(test_model_freq)

sub_hurdle = hurdle(substance_days ~ 1 , data = c_mat_clean, dist = "negbin", zero.dist = "binomial", weights = ipw_var)

sat_log_lin = glm(log(sat) ~ 1 , data = c_mat_clean, weights = ipw_var)

dep_anx_hurdle = hurdle(dep_anx ~ 1 , data = c_mat_clean, dist = "negbin", zero.dist = "binomial", weights = ipw_var)

```


Load of REDCap data
REDCap_rawdata_11.13.2020_C-MAT
```{r}
setwd("T:/CRI_Research/telehealth_evaluation/CCHBC_big_picture/social_determinants_of_health_docs/Data/mat_data")

c_mat_redcap = read.csv("REDCap_rawdata_11.13.2020_C-MAT.csv", header = TRUE)
head(c_mat_redcap)
c_mat_redcap_6_month = subset(c_mat_redcap,redcap_event_name  == "6_month_followup_arm_1")
dim(c_mat_redcap_6_month)
c_mat_redcap_6_month$ssi_aod_date  = mdy(c_mat_redcap_6_month$ssi_aod_date) 
range(c_mat_redcap_6_month$ssi_aod_date, na.rm = TRUE)

c_mat_redcap_6_month = subset(c_mat_redcap_6_month, ssi_aod_date > "2000-01-01") 
c_mat_redcap_6_month$telehealth = ifelse(c_mat_redcap_6_month$ssi_aod_date >= "2020-04-01", 1, 0)
library(prettyR)
dim(c_mat_redcap_6_month)[1]
describe.factor(c_mat_redcap_6_month$telehealth)
#### Not enough data
```
Load in BARC-10 data
Change assessment date
Identify duplicate BARC-10 
Subset to only clients with three or less admins 
Remove March
Create telehealth variable
Bayesian log non-inferior of 10% for RCS
Do hurdle for hospital days and ER visits
```{r}
setwd("T:/CRI_Research/telehealth_evaluation/mat_data")
barc_10_mat = read.csv("CIL BARC-10 and MAT Data 2020-11-13.csv", header = TRUE)

barc_10_mat_clean = barc_10_mat %>%
  mutate(id_date = paste0(SourceClient_ID, AssessmentDate)) %>%
  ## keep the first instance of any duplicates
  distinct(id_date, .keep_all = TRUE) %>%
  mutate(AssessmentDate = mdy(AssessmentDate)) %>%
  group_by(SourceClient_ID) %>% 
    mutate(time = row_number()-1) %>%
  ### Just filter for those who had at least 3 admins not matached pairs
  filter(time <= 2) %>%
  filter(AssessmentDate <= "2020-2-28" | AssessmentDate >= "2020-04-01") %>%
  select(SourceClient_ID, AssessmentDate, rcs_10_item_score, rle_days_hosp_med, rle_days_hosp_psych, rle_er_visits, time) %>%
  mutate(telehealth = if_else(AssessmentDate >= "2020-04-01", 1, 0)) %>%
  mutate(face_to_face = if_else(AssessmentDate >= "2020-04-01", 0, 1))
prettyR::describe.factor(barc_10_mat_clean$telehealth)
#Successfully removed March
#barc_10_mat[order(barc_10_mat$AssessmentDate),][1200:1300,]

##### Create matched pairs
time_0  = barc_10_mat_clean %>%
  filter(time == 0)

time_1 = barc_10_mat_clean %>%
  filter(time == 1)

time_2 = barc_10_mat_clean %>%
  filter(time == 2)
time_2

time_0_1 = time_0 %>% inner_join(time_1, by = "SourceClient_ID")
dim(time_0_1)
time_0_1_2 = time_0_1 %>% inner_join(time_2, by = "SourceClient_ID")
time_0_1_2 = data.frame(time_0_1_2)
library(reshape2)
barc_10_mat_clean_long =  reshape(time_0_1_2, varying = list(c("AssessmentDate.x", "AssessmentDate.y", "AssessmentDate"), c("rcs_10_item_score.x", "rcs_10_item_score.y", "rcs_10_item_score"), c("rle_days_hosp_med.x", "rle_days_hosp_med.y", "rle_days_hosp_med"), c("rle_days_hosp_psych.x", "rle_days_hosp_psych.y", "rle_days_hosp_psych"),c("rle_er_visits.x", "rle_er_visits.y", "rle_er_visits"), c("time.x", "time.y", "time"),  c("telehealth.x", "telehealth.y", "telehealth"), c("face_to_face.x", "face_to_face.y", "face_to_face")), times = c(0,1,2), direction = "long")
barc_10_mat_clean_long
```

Do this earlier clean data
```{r}
apply(barc_10_mat_clean_long[5:7], 2, function(x){describe.factor(x)})
test =  barc_10_mat_clean_long %>%
  rowwise() %>%
  mutate(hos_er = sum(c_across(5:7)))
```
Develop IPW


Try Bayesian log with BARC-10 scores
```{r}

my_prior = normal(location = 0, scale = .2, autoscale = FALSE)
stan_linear_log = stan_glm(rcs_10_item_score.x ~ time*face_to_face.x + MDD.x +gender_minority.x +racial_minority.x + IL.x + FL.x + Form_DESC.x, data = clean_compare_dat_long, weights = ipw_var, prior = my_prior, seed =  124)
stan_linear_log_sum = round(stan_linear_log$stan_summary[,c(1,3,4,10)],4)
## To get percentage change interpretation need to exp the parameter estimates
stan_linear_log_sum = round(exp(stan_linear_log_sum),3)
### Creates a percentage instead 1 + % 
stan_linear_log_sum= stan_linear_log_sum - 1
stan_linear_log_sum
posterior_face =  as.data.frame(stan_linear_log)
### Reverse for percentage change
stan_linear_log = stan_glm(log_PHQ9_Total.x ~ time*telehealth + MDD.x +gender_minority.x +racial_minority.x + IL.x + FL.x, data = clean_compare_dat_long,  seed = 124,  weights = ipw_var, prior = my_prior)
stan_linear_log_sum = round(stan_linear_log$stan_summary[,c(1,3,4,10)],4)
## To get percentage change interpretation need to exp the parameter estimates
stan_linear_log_sum = round(exp(stan_linear_log_sum),3)
### Creates a percentage instead 1 + % 
stan_linear_log_sum= stan_linear_log_sum - 1
stan_linear_log_sum

```














