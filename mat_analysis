---
title: "Test"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
CMAT data
Loading data and cleaning
```{r}
library(lubridate)
library(dplyr)
library(naniar)
library(tidyr)
setwd("T:/CRI_Research/telehealth_evaluation/CCHBC_big_picture/social_determinants_of_health_docs/Data/mat_data")
c_mat = read.csv("SPARS_rawdata_11.13.2020_C-MAT.csv", header = TRUE, na.strings = c(-9, -1, -8, -7, -6, -5))

c_mat_clean = c_mat %>%
  ### Only 6-months data because you don't have enough for pre and post with telehealth
  filter(InterviewType == 2) %>%
  mutate(InterviewDate = mdy(InterviewDate)) %>%
  ### Remove data with NAs for dates
  filter(InterviewDate > "2000-01-01") %>%
  mutate(telehealth = if_else(InterviewDate >= "2020-04-01", 1, 0)) %>%
  select(ClientID, InterviewType, InterviewDate, Icd10CodeOne, Age, Employment, Gender, HispanicLatino, RaceWhite, DAUseAlcoholDays, DAUseIllegDrugsDays, CocaineCrackDays, MarijuanaHashDays, OpiatesHeroinDays, OpiatesMorphineDays, OpiatesDiluadidDays, OpiatesDemerolDays, OpiatesPercocetDays, OpiatesDarvonDays, OpiatesCodeineDays, OpiatesTylenolDays, OpiatesOxycoDays, NonPresMethadoneDays, HallucPsychDays, MethamDays, BenzodiazepinesDays, BarbituatesDays, NonPrescGhbDays, KetamineDays, OtherTranquilizersDays, InhalantsDays, OtherIllegalDrugsDays, InjectedDrugs, LivingWhere, LivingConditionsSatisfaction, ImpactStress, ImpactActivity, ImpactEmotional, EducationYears, ArrestedDays, NrCrimes, LifeQuality, HealthSatisfaction, EnoughEnergyForEverydayLife, PerformDailyActivitiesSatisfaction, SelfSatisfaction, Depression, Anxiety, ViolentBehavior, Suicide, PsycholEmotMedication, PsycholEmotImpact, AnyViolence, PhysicallyHurt, telehealth) %>%
  rowwise() %>% 
      mutate(
        substance_days = mean(c_across(11:33)),
        impact = mean(c_across(37:39)),
        sat = mean(c_across(43:47)),
        dep_anx = mean(c_across(48:49)),
        vio_suc = mean(c_across(50:51))) %>%
  drop_na()

miss_var_summary(c_mat_clean)


```
CMAT descriptives
```{r}
dim(c_mat_clean)
apply(c_mat_clean[50:60], 2, function(x){describe.factor(x)})
summary(c_mat_clean)
```
CMAT days, sat, and dep_anx just mean differences
Sub use is in average days and depression and anxieity is in average days
For the specifics about the type of MAT talk to Ellen
```{r}
library(descr)
library(tibble)
means_compare_dat = c_mat_month6_complete[c("impact", "substance_days", "sat", "dep_anx")]
out_means_compare = list()
p_change_out = list()
wil_out = list()

for(i in 1:length(means_compare_dat)){
  out_means_compare[[i]] = compmeans(means_compare_dat[[i]], c_mat_month6_complete$telehealth)
  p_change_out[[i]] = round((out_means_compare[[i]][2,1] - out_means_compare[[i]][1,1]) / out_means_compare[[i]][1,1],2)
  wil_out[[i]] = wilcox.test(means_compare_dat[[i]] ~ c_mat_month6_complete$telehealth)
}

out_results_list = c(out_means_compare, p_change_out, wil_out) 
for(i in 1:length(out_results_list)){
  
}

names(out_means_compare) = c("impact", "substance_days", "sat", "dep_anx")
out_means_compare
names(p_change_out) = c("impact", "substance_days", "sat", "dep_anx")
p_change_out
names(wil_out) = c("impact", "substance_days", "sat", "dep_anx")
wil_out
```

Load of REDCap data
REDCap_rawdata_11.13.2020_C-MAT
```{r}
setwd("T:/CRI_Research/telehealth_evaluation/CCHBC_big_picture/social_determinants_of_health_docs/Data/mat_data")

c_mat_redcap = read.csv("REDCap_rawdata_11.13.2020_C-MAT.csv", header = TRUE)
head(c_mat_redcap)
c_mat_redcap_6_month = subset(c_mat_redcap,redcap_event_name  == "6_month_followup_arm_1")
dim(c_mat_redcap_6_month)
c_mat_redcap_6_month$ssi_aod_date  = mdy(c_mat_redcap_6_month$ssi_aod_date) 
range(c_mat_redcap_6_month$ssi_aod_date, na.rm = TRUE)

c_mat_redcap_6_month = subset(c_mat_redcap_6_month, ssi_aod_date > "2000-01-01") 
c_mat_redcap_6_month$telehealth = ifelse(c_mat_redcap_6_month$ssi_aod_date >= "2020-04-01", 1, 0)
library(prettyR)
dim(c_mat_redcap_6_month)[1]
describe.factor(c_mat_redcap_6_month$telehealth)
#### Not enough data
```
Load in BARC-10 data
Change assessment date
Identify duplicate BARC-10 
Subset to only clients with three or less admins 
Remove March
Create telehealth variable
Bayesian log non-inferior of 10% for RCS
Do hurdle for hospital days and ER visits
```{r}
setwd("T:/CRI_Research/telehealth_evaluation/mat_data")
barc_10_mat = read.csv("CIL BARC-10 and MAT Data 2020-11-13.csv", header = TRUE)

barc_10_mat_clean = barc_10_mat %>%
  mutate(id_date = paste0(SourceClient_ID, AssessmentDate)) %>%
  ## keep the first instance of any duplicates
  distinct(id_date, .keep_all = TRUE) %>%
  mutate(AssessmentDate = mdy(AssessmentDate)) %>%
  group_by(SourceClient_ID) %>% 
    mutate(time = row_number()-1) %>%
  ### Just filter for those who had at least 3 admins not matached pairs
  filter(time <= 2) %>%
  filter(AssessmentDate <= "2020-2-28" | AssessmentDate >= "2020-04-01") %>%
  select(SourceClient_ID, AssessmentDate, rcs_10_item_score, rle_days_hosp_med, rle_days_hosp_psych, rle_er_visits, time) %>%
  mutate(telehealth = if_else(AssessmentDate >= "2020-04-01", 1, 0)) %>%
  mutate(face_to_face = if_else(AssessmentDate >= "2020-04-01", 0, 1))
prettyR::describe.factor(barc_10_mat_clean$telehealth)
#Successfully removed March
#barc_10_mat[order(barc_10_mat$AssessmentDate),][1200:1300,]

##### Create matched pairs
time_0  = barc_10_mat_clean %>%
  filter(time == 0)

time_1 = barc_10_mat_clean %>%
  filter(time == 1)

time_2 = barc_10_mat_clean %>%
  filter(time == 2)
time_2

time_0_1 = time_0 %>% inner_join(time_1, by = "SourceClient_ID")
dim(time_0_1)
time_0_1_2 = time_0_1 %>% inner_join(time_2, by = "SourceClient_ID")
time_0_1_2 = data.frame(time_0_1_2)
library(reshape2)
barc_10_mat_clean_long =  reshape(time_0_1_2, varying = list(c("AssessmentDate.x", "AssessmentDate.y", "AssessmentDate"), c("rcs_10_item_score.x", "rcs_10_item_score.y", "rcs_10_item_score"), c("rle_days_hosp_med.x", "rle_days_hosp_med.y", "rle_days_hosp_med"), c("rle_days_hosp_psych.x", "rle_days_hosp_psych.y", "rle_days_hosp_psych"),c("rle_er_visits.x", "rle_er_visits.y", "rle_er_visits"), c("time.x", "time.y", "time"),  c("telehealth.x", "telehealth.y", "telehealth"), c("face_to_face.x", "face_to_face.y", "face_to_face")), times = c(0,1,2), direction = "long")
barc_10_mat_clean_long
```
Non-inferiority analysis with Bayesian 
Try without log 
rowwise() %>% 
      mutate(
        substance_days = mean(c_across(11:33))
        
Do this earlier clean data
```{r}
apply(barc_10_mat_clean_long[5:7], 2, function(x){describe.factor(x)})
test =  barc_10_mat_clean_long %>%
  rowwise() %>%
  mutate(hos_er = sum(c_across(5:7)))
```
Develop IPW


Try Bayesian log with BARC-10 scores
```{r}

my_prior = normal(location = 0, scale = .2, autoscale = FALSE)
stan_linear_log = stan_glm(rcs_10_item_score.x ~ time*face_to_face.x + MDD.x +gender_minority.x +racial_minority.x + IL.x + FL.x + Form_DESC.x, data = clean_compare_dat_long, weights = ipw_var, prior = my_prior, seed =  124)
stan_linear_log_sum = round(stan_linear_log$stan_summary[,c(1,3,4,10)],4)
## To get percentage change interpretation need to exp the parameter estimates
stan_linear_log_sum = round(exp(stan_linear_log_sum),3)
### Creates a percentage instead 1 + % 
stan_linear_log_sum= stan_linear_log_sum - 1
stan_linear_log_sum
posterior_face =  as.data.frame(stan_linear_log)
### Reverse for percentage change
stan_linear_log = stan_glm(log_PHQ9_Total.x ~ time*telehealth + MDD.x +gender_minority.x +racial_minority.x + IL.x + FL.x, data = clean_compare_dat_long,  seed = 124,  weights = ipw_var, prior = my_prior)
stan_linear_log_sum = round(stan_linear_log$stan_summary[,c(1,3,4,10)],4)
## To get percentage change interpretation need to exp the parameter estimates
stan_linear_log_sum = round(exp(stan_linear_log_sum),3)
### Creates a percentage instead 1 + % 
stan_linear_log_sum= stan_linear_log_sum - 1
stan_linear_log_sum

```














